---
title: "Networks"
author: "Jona Leka"
date: "`r Sys.Date()`"
output: html_document
---


```{r}
# load
library(dplyr)
library(tidyr)
library(pander)
library(ggplot2)
library(gridExtra)
library(Hmisc)
library(igraph)
library(GGally)
library(intergraph)
library(nnet)
library(bootnet)
library(qgraph)
library(tidyverse)
library(psych)
```


```{r}
df21recoded2<-Climate_Survey_febmar_2021_microdata
df22recoded2<-Climate_Survey_2022_marapril_microdata
```


```{r}
# Check for missing values in each column
sapply(df21recoded2_NA, function(x) sum(is.na(x)))
```

```{r}
df21recoded_subset <- subset(df21recoded2_NA, select=-c(urbanicity,age,gender,country))
df22recoded_subset <- subset(df22recoded2_NA, select=-c(urbanicity,age,gender,country))
```



```{r}
# convert to numeric after recoding
library(dplyr)

df21recoded_subset <- df21recoded_subset %>%
  mutate(across(everything(), as.numeric))

df22recoded_subset <- df22recoded_subset %>%
  mutate(across(everything(), as.numeric))

df21recoded2_NA <- df21recoded2_NA %>%
  mutate(across(everything(), as.numeric))

df22recoded2_NA <- df22recoded2_NA %>%
  mutate(across(everything(), as.numeric))

```



```{r}
#explore data
summary(df21recoded_subset)
hist(df21recoded_subset$climate_beliefs)
```

```{r}
library(psych)
description21<- describe(df21recoded_subset)
print(description21)
```
```{r}

age_frequencies <- table(df21recoded2_NA$age)
age_percentages <- (age_frequencies / sum(age_frequencies)) * 100
print(age_percentages)


```
```{r}
gender_frequencies <- table(df21recoded2_NA$gender)
gender_percentages <- (gender_frequencies / sum(gender_frequencies)) * 100
print(gender_percentages)
```
```{r}

age_frequencies2 <- table(df22recoded2_NA$age)
age_percentages2 <- (age_frequencies2 / sum(age_frequencies2)) * 100
print(age_percentages2)
```

```{r}
gender_frequencies2 <- table(df22recoded2_NA$gender)
gender_percentages2 <- (gender_frequencies2 / sum(gender_frequencies2)) * 100
print(gender_percentages2)
```

```{r}
# List of variable names
variables <- c( "climate_awareness", "climate_happening", "climate_beliefs", 
               "climate_worry", "harm_personally", "harm_future_gen", "climate_importance", 
               "gov_priority", "gov_more_less", "paris_support_oppose", "economic_impact", 
               "renewable_more_less", "fossil_more_less", "climate_action", "climate_info")
```


```{r}
for (variable in variables) {
  hist(df21recoded_subset[[variable]], main = paste("Histogram of", variable), xlab = variable)
}
for (variable in variables) {
  plot(density(df21recoded_subset[[variable]], na.rm = TRUE), main = paste("Density Plot of", variable), xlab = variable)
}

```

```{r}
# estimating a network with polychoric correlations as input and GGM with Extended Bayesian Criteron and graphical LASSO regularization
Network21_EBIC_poly <- estimateNetwork(df21recoded_subset,default = "EBICglasso", tuning = .5, corMethod = "cor_auto")
```
```{r}
str(df21recoded_subset)
```

```{r}
png("Network21_EBIC_poly.png", width = 2000, height = 1500, res = 300)
plot(Network21_EBIC_poly, layout = "spring")

```

```{r}
png("Network21_EBIC_poly_c.png", width = 2000, height = 1500, res = 300)
centralityPlot(Network21_EBIC_poly, include = c("Strength", "Betweenness", "Closeness"))
```


```{r}
# nonparametric bootstrap for stability of edges and of edge differences
set.seed(1)
# Edge weight accuracy test
boot1 <-bootnet(Network21_EBIC_poly, nBoots = 1000,type="nonparametric",
nCores = 8, statistics = "edge")
plot(boot1, labels = FALSE,
  order = "sample")
```

```{r}
png("bootnet1CI_plot.png", width = 2000, height = 1500)
## CI around edges
plot(boot1, plot="area", order="sample",font_size = 9, legend= FALSE)
```


```{r}
png("bootnet1_diff.png", width = 2000, height = 1500)
## differences between edges
plot(boot1, plot="difference", order="sample", onlyNonZero=FALSE, labels=TRUE)
```


```{r eval=FALSE}
# case dropping bootstrap for centrality stability
boot1_centrality <- bootnet(Network21_EBIC_poly,default="EBICglasso", nBoots = 2500, type = "case", nCores = 8, computeCentrality = TRUE, statistics=c("strength"), caseMin = .05,caseMax = .95,caseN=19)
# visualize results
# Plotting centrality stability
plot(boot1_centrality, type = "CS", order="mean")
plot(boot1_centrality, type = "centrality")
```
```{r}

boot_data <- boot1_centrality$bootTable

# Calculate the confidence intervals for each node
library(dplyr)

confidence_intervals <- boot_data %>%
  group_by(node1) %>%
  summarise(lower_ci = quantile(value, probs = 0.025),
            upper_ci = quantile(value, probs = 0.975),
            mean_strength = mean(value)) %>%
  ungroup()

library(ggplot2)

ggplot(confidence_intervals, aes(x = node1, y = mean_strength)) +
  geom_point() +
  geom_segment(aes(x = node1, xend = node1, y = lower_ci, yend = upper_ci), color = "blue") +
  theme_minimal() +
  coord_flip() # Flipping coordinates for a horizontal lollipop chart


```

```{r}
boot_data <- boot1_centrality$bootTable

# Calculate the confidence intervals for each node
library(dplyr)

confidence_intervals <- boot_data %>%
  group_by(node1) %>%
  summarise(lower_ci = quantile(value, probs = 0.025),
            upper_ci = quantile(value, probs = 0.975),
            mean_strength = mean(value)) %>%
  ungroup() %>%
  arrange(desc(mean_strength)) # Add this line to arrange by mean_strength


ggplot(confidence_intervals, aes(x = reorder(node1, -mean_strength), y = mean_strength)) +
  geom_point() +
  geom_segment(aes(x = node1, xend = node1, y = lower_ci, yend = upper_ci), color = "blue") +
  theme_minimal() +
  coord_flip() # Flipping coordinates for a horizontal lollipop chart

```
```{r}
png("Boot1_centralitystability.png", width = 2000, height = 1500, res = 300)
# Assuming boot1_centrality is your list object and it has been loaded in R
boot_data <- boot1_centrality$bootTable

# Calculate the confidence intervals for each node
library(dplyr)

confidence_intervals <- boot_data %>%
  group_by(node1) %>%
  summarise(lower_ci = quantile(value, probs = 0.025),
            upper_ci = quantile(value, probs = 0.975),
            mean_strength = mean(value)) %>%
  ungroup() %>%
  arrange(desc(mean_strength)) # Arrange by mean_strength

library(ggplot2)

ggplot(confidence_intervals, aes(x = reorder(node1, -mean_strength), y = mean_strength)) +
  geom_point() +
  geom_segment(aes(x = node1, xend = node1, y = lower_ci, yend = upper_ci), color = "blue") +
  theme_minimal() +
  coord_flip() + # Flipping coordinates for a horizontal lollipop chart
  labs(y = "Centrality (node strength)", x = "") # Renaming the y-axis and removing the x-axis label

```
```{r}
boot_data <- boot1_centrality$bootTable

confidence_intervals <- boot_data %>%
  group_by(node1) %>%
  summarise(lower_ci = quantile(value, probs = 0.025),
            upper_ci = quantile(value, probs = 0.975),
            mean_strength = mean(value)) %>%
  ungroup() %>%
  arrange(desc(mean_strength)) # Arrange by mean_strength

ggplot(confidence_intervals, aes(x = reorder(node1, -mean_strength), y = mean_strength)) +
  geom_ribbon(aes(ymin = lower_ci, ymax = upper_ci), fill = "grey", alpha = 0.5) +
  geom_point() +
  geom_segment(aes(x = node1, xend = node1, y = lower_ci, yend = upper_ci), color = "black") +
  theme_minimal() +
  coord_flip() + # Flipping coordinates for a horizontal lollipop chart
  labs(y = "Centrality (node strength)", x = "") # Renaming the y-axis and removing the x-axis label

```

```{r}
confidence_intervals <- boot_data %>%
  group_by(node1) %>%
  summarise(lower_ci = quantile(value, probs = 0.025),
            upper_ci = quantile(value, probs = 0.975),
            mean_strength = mean(value)) %>%
  ungroup()

ggplot(confidence_intervals, aes(x = node1, y = mean_strength)) +
  geom_segment(aes(x = node1, xend = node1, y = lower_ci, yend = upper_ci), color = "grey") + # CI lines in grey
  geom_point(size = 3, color = "black") + # Increase point size and set to black
  theme_minimal() +
  coord_flip() + # Flipping coordinates for a horizontal lollipop chart
  theme(
    panel.grid.major.y = element_blank(), # Remove horizontal grid lines
    panel.grid.major.x = element_line(color = "grey", size = 0.2), # Lighten the vertical grid lines
    panel.background = element_rect(fill = "white"), # Set panel background to white
    axis.text.y = element_text(size = 7) # Adjust text size for y axis labels if necessary
  )

```

```{r}
plot(boot1_centrality, perNode=TRUE, "strength")
```


```{r}
# estimate correlation stability coefficients for strength centrality
corStability(boot1_centrality)
```



```{r}
summary(boot1)
summary(boot1_centrality)
```



```{r}
# using the default functions of bootnet, estimating network with pcor (without transformation)
Network21_EBIC_pcor <- estimateNetwork(df21recoded_subset,
 default = "EBICglasso",tuning = 0.5)

#with threshold (certain nodes have been dropped here as per below graph)
network_pcor21 <- estimateNetwork(df21recoded_subset, default = "pcor", threshold = "sig", alpha = 0.05)
```


```{r}
plot(Network21_EBIC_pcor, layout = "spring")
```
```{r}
centralityPlot(Network21_EBIC_pcor, include = c("Strength", "Betweenness", "Closeness"))
```


```{r}
plot(network_pcor21, layout = "spring")
```
```{r}
centralityPlot(network_pcor21, include = c("Strength", "Betweenness", "Closeness"))


```




```{r}
centrality_results <- centrality(Network21_EBIC_poly)
print(centrality_results)
```



```{r}
centralityPlot(list(Network21_EBIC_pcor=Network21_EBIC_pcor,network_pcor21=network_pcor21))
```


```{r}
library("qgraph")
plot(Network21_EBIC_pcor, layout = "spring")
```

```{r}
##### COMPARE centrality
centralityPlot(list(Network21_EBIC_poly=Network21_EBIC_poly,Network21_EBIC_pcor=Network21_EBIC_pcor))
```
```{r eval=FALSE}
# Edge-weight accuracy test 
boot1_b <-bootnet(Network21_EBIC_pcor, nBoots = 1000, type="nonparametric",
nCores = 8)
```
```{r eval=FALSE}

# Edge-weight accuracy test plot
plot(boot1_b, labels = FALSE,
  order = "sample")

```
```{r eval=FALSE}
summary(boot1_b)
```

```{r eval=FALSE}
plot(boot1_b)
```


```{r eval=FALSE}
#Testing for significant differences
differenceTest(boot1_b,1,2,"strength")

```
Plot the difference tests of node strength between all pairs of edge-weights. Here the plot argument has to be used because the function normally defaults to plotting bootstrapped CIs for edge-weights, the onlyNonZero argument sets so that only edges are shown that are nonzero in the estimated network, and order = "sample" orders the edge-weights from the most positive to the most negative edge-weight in the sample network.
```{r eval=FALSE}
plot(boot1_b, "edge", plot = "difference", onlyNonZero = TRUE, order = "sample")

```
We can use a similar code for comparing node strength.In which we did not have to specify the plot argument as it is set to the "difference" by default when the statistic is a centrality index.
```{r eval=FALSE}
plot(boot1_b, "strength")
```

```{r eval=FALSE}
#centrality stability test
boot2_b <- bootnet(Network21_EBIC_pcor, nBoots = 1000, type = "case", nCores = 8)

#Zoom in on specific nodes
plot(boot2_b, perNode=TRUE, "strength")

```

```{r}
plot(network_pcor21)
```



```{r eval=FALSE}
# Run bootstrap on pcor with threshold

# Edge-weight accuracy test 
boot1_threhold <-bootnet(network_pcor21, nBoots = 1000, type="nonparametric",
nCores = 8)
```

```{r eval=FALSE}
plot(boot1_threhold)
plot(boot1_threhold, labels = FALSE,
  order = "sample")
```

```{r eval=FALSE}
#centrality stability test
boot_centrality_threshold <- bootnet(network_pcor21, nBoots = 1000, type = "case", nCores = 8)

#Zoom in on specific nodes
plot(boot_centrality_threshold, perNode=TRUE, "strength")
```

The NPN transformation converts the ranks of each variable into the quantiles of a standard normal distribution, which helps to reduce the impact of outliers and can make the distribution of each variable more symmetric.

```{r}
# Estimate network 2 - Apply nonparanormal transformation to data first, then estimate network with EBIC using partial correlations - [skip this]
library(huge)
data21_transformed<-huge.npn(df21recoded_subset)
```

```{r}
summary(data21_transformed)
```

```{r}
data21_transformed <- as.data.frame(data21_transformed)

```

```{r}
# Install and load the psych package

library(psych)

# Compute summary statistics for all variables
description21_transformed<- describe(data21_transformed)
print(description21_transformed)


```

```{r}
for (variable in variables) {
  hist(data21_transformed[[variable]], main = paste("Histogram of", variable), xlab = variable)
}
```

```{r}
# Create density plots for each variable
for (variable in variables) {
  plot(density(data21_transformed[[variable]], na.rm = TRUE), main = paste("Density Plot of", variable), xlab = variable)
}
```
```{r}
# estiimating a network with pearson cor as input and GGM with Extended Bayesian Criteron and graphical LASSO regularization
Network21_transformed <- estimateNetwork(data21_transformed,default = "EBICglasso", tuning = .5, corMethod = "cor")
```
```{r}
plot(Network21_transformed, layout = 'spring') 
```
```{r}
centralityPlot(Network21_transformed, include = c("Strength", "Betweenness", "Closeness"))
```


```{r}
# estimating a network with npn transformation as input and GGM with Extended Bayesian Criteron and graphical LASSO regularization
Network21_npn <- estimateNetwork(df21recoded_subset,default = "EBICglasso", tuning = 0.5, corMethod = "npn")
```
```{r}
plot(Network21_npn, layout = 'spring') 
```
```{r}
centralityPlot(Network21_npn, include = c("Strength", "Betweenness", "Closeness"))
```
```{r eval=FALSE}
# Edge weight accuracy network pcor with threshold
boot21__accuracy_threhold <-bootnet(network_pcor21, nBoots = 1000, type="nonparametric",
nCores = 8)
```
```{r eval=FALSE}
plot(boot21__accuracy_threhold, labels = FALSE,
  order = "sample")
```

```{r eval=FALSE}
# Edge weight accuracy network npn test
boot21_npn <-bootnet(Network21_npn, nBoots = 1000, type="nonparametric",
nCores = 8)
```


```{r eval=FALSE}
# Edge-weight accuracy test plot
plot(boot21_npn, labels = FALSE,
  order = "sample")
```
```{r eval=FALSE}
#Plot split-0 BCIs (labels =False to turn off labels on the y axis if network has many nodes)
plot(boot21_npn, plot="interval", order= "sample", split0= TRUE, labels= FALSE)

```
```{r eval=FALSE}
#Centrality differences plot
plot(boot21_npn,"strength", order="sample")

```
```{r eval=FALSE}
# Accuracy of centrality indeces
boot_npn_accuracy <- bootnet(Network21_npn, nBoots=1000, nCores=8, type="case")
plot(boot_npn_accuracy)

```
```{r eval=FALSE}
plot(boot_npn_accuracy)
```

```{r eval=FALSE}
#Zoom in on specific nodes
plot(boot_npn_accuracy, perNode=TRUE, "strength")
```

```{r}
# compare network npn with the one where data was transformed prior to estimation
centralityPlot(list(Network21_npn=Network21_npn,Network21_transformed= Network21_transformed))
```
They're identical. 

```{r}
centralityPlot(Network21_npn, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(Network21_EBIC_pcor, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(network_pcor21, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(Network21_EBIC_poly, include = c("Strength", "Betweenness", "Closeness"))
```

```{r}
##### COMPARE centrality
centralityPlot(list(Network21_EBIC_poly=Network21_EBIC_poly,Network21_EBIC_pcor=Network21_EBIC_pcor,Network21_npn=Network21_npn,network_pcor21=network_pcor21,Network21_transformed=Network21_transformed))
```
```{r}
library (bootnet)
library(qgraph)
centralityPlot(list(Network21_EBIC_poly=Network21_EBIC_poly))
```

```{r}
##### COMPARE centrality (MAIN NETWORKS 2 with pcor with and without nonparanormal transformation, and 1 with polychoric cor without any transformation)
centralityPlot(list(Network21_EBIC_poly=Network21_EBIC_poly,Network21_EBIC_pcor=Network21_EBIC_pcor,Network21_npn=Network21_npn, network_pcor21=network_pcor21), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
centralityPlot(list(Network21_EBIC_poly=Network21_EBIC_poly), include = c("Strength", "Betweenness", "Closeness"))
```




```{r}
#comparing netwroks with pcor with and without nonporanormal transformation
centralityPlot(list(Network21_EBIC_pcor=Network21_EBIC_pcor,Network21_npn=Network21_npn))
```
```{r}
plot(Network21_EBIC_poly)
```


```{r}
######Analyze data 2022
# Compute summary statistics for all variables
summary_stats22 <- describe(df22recoded_subset)
print(summary_stats22)
```


```{r}
##Explore data22
variables22 <- names(df22recoded_subset)
# Create histograms for each variable
for (variable in variables22) {
  hist(df22recoded_subset[[variable]], main = paste("Histogram of", variable), xlab = variable)
}

```

```{r}
# Create density plots for each variable
for (variable in variables22) {
  plot(density(df22recoded_subset[[variable]], na.rm = TRUE), main = paste("Density Plot of", variable), xlab = variable)
}

```

```{r}
library(psych)
description22<- describe(df22recoded_subset)
print(description22)
```
```{r}
# Estimate network for data 22 with polychoric cor as input and EBIC with LASSO
Network22_EBIC_poly <- estimateNetwork(df22recoded_subset,default = "EBICglasso", tuning = .5, corMethod = "cor_auto")
```
```{r}
png("Network22_EBIC_poly.png", width = 2000, height = 1500, res = 300)
plot(Network22_EBIC_poly)
```
```{r}
summary(Network22_EBIC_poly$graph)
```

```{r}
png("Network21_EBIC_poly_c.png", width = 2000, height = 1500, res = 300)
centralityPlot(Network22_EBIC_poly, include = c("Strength", "Betweenness", "Closeness"))
```

```{r}
plot(Network22_EBIC_poly, layout="spring")
```
```{r}
##accuracy tests for 22

# Edge weight accuracy 
boot_2 <-bootnet(Network22_EBIC_poly, nBoots = 1000, type="nonparametric",
nCores = 8)
```


```{r}
png("bootnet2CI_plot.png", width = 2000, height = 1500)
# Plot CI around edge weights
plot(boot_2, plot="area", order="sample",font_size = 9, legend= FALSE)

```
Given that bootstrapping can be computationally intensive, save the results with saveRDS(boot_2, file = "boot_2.RDS") and load them later with boot_2 <– readRDS("boot_2.RDS") so we need not estimate bootstraps again every time we run the R code.
```{r}
#Plot split-0 BCIs (labels =False to turn off labels on the y axis if network has many nodes)
plot(boot_2, plot="interval", order= "sample", split0= TRUE, labels= FALSE)
```
```{r eval=FALSE}
# save file
saveRDS(boot_2, file = "boot_2.RDS")
#check later
boot_2 <- readRDS("boot_2.RDS")
```

```{r eval=FALSE}
#Edge weights difference plot (argument onlyNonZero=TRUE to show only edges that were included as non-zero) 
plot(boot_2,"edge",plot="difference",onlyNonZero=TRUE,order="sample")
```

```{r eval=FALSE}
#Centrality differences plot
plot(boot_2,"strength", order="sample")
```
```{r}
# Accuracy of centrality indeces
# case dropping bootstrap for centrality stability
boot2_centrality <- bootnet(Network22_EBIC_poly,default="EBICglasso", nBoots = 1000, type = "case", nCores = 8, computeCentrality = TRUE, statistics=c("strength"), caseMin = .05,caseMax = .95,caseN=19)
boot_22b <- bootnet(Network22_EBIC_poly, nBoots=1000, nCores=8, type="case")
plot(boot_22b)

#Zoom in on specific nodes
plot(boot_22b, perNode=TRUE, "strength")
```
The information of the case-drop bootstrap can be summarized in the correlation stability (CS) coefficient, where ‘CS(cor = 0.7)’ represents the maximum proportion of cases that can be dropped, such that in 95% of the samples the correlation between original centrality indices and centrality of networks based on subsets is 0.7 or higher (Network Psychometrics with R, p. 242)

```{r}
corStability(boot2_centrality)
plot(boot2_centrality, statistics = c("strength"), CIstyle = "quantiles")
```
```{r}
# Check the data types
boot2_centrality$sampleTable$value
```
```{r}
png("Boot2_centralitystability.png", width = 2000, height = 1500, res = 300)
boot_data2 <- boot2_centrality$bootTable

# Calculate the confidence intervals for each node
confidence_intervals <- boot_data2 %>%
  group_by(node1) %>%
  summarise(lower_ci = quantile(value, probs = 0.025),
            upper_ci = quantile(value, probs = 0.975),
            mean_strength = mean(value)) %>%
  ungroup() %>%
  arrange(desc(mean_strength)) # Arrange by mean_strength

ggplot(confidence_intervals, aes(x = reorder(node1, -mean_strength), y = mean_strength)) +
  geom_point() +
  geom_segment(aes(x = node1, xend = node1, y = lower_ci, yend = upper_ci), color = "blue") +
  theme_minimal() +
  coord_flip() + # Flipping coordinates for a horizontal lollipop chart
  labs(y = "Centrality (node strength)", x = "") # Renaming the y-axis and removing the x-axis label

```



```{r}
# Estimate network 22 with npn and pcor
Network22_npn <- estimateNetwork(df22recoded_subset,default = "EBICglasso", tuning = 0.5, corMethod = "npn")
Network22_EBIC_pcor<- estimateNetwork(df22recoded_subset, default = "EBICglasso",tuning = 0.5,corMethod = "cor")
network22_pcor <- estimateNetwork(df22recoded_subset, default = "pcor", threshold = "sig", alpha = 0.05)

```
```{r}
centralityPlot(Network22_npn, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(Network22_EBIC_pcor, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(network22_pcor, include = c("Strength", "Betweenness", "Closeness"))
```
```{r eval=FALSE}
# Edge weight accuracy  tests for 22 remainder
boot_2_pcor <-bootnet(Network22_EBIC_pcor, nBoots = 1000, type="nonparametric",
nCores = 8)
```
```{r eval=FALSE}
# Edge weight accuracy 
boot_22_threshold <-bootnet(Network22_npn, nBoots = 1000, type="nonparametric",
nCores = 8)
```

```{r eval=FALSE}
boot_22_npn <-bootnet(network22_pcor, nBoots = 1000, type="nonparametric",
nCores = 8)
```
```{r eval=FALSE}
plot(boot_2_pcor)
plot(boot_22_threshold)
plot(boot_22_npn)
```
```{r eval=FALSE}
plot(boot_2_pcor, order="sample")
plot(boot_22_threshold, order="sample")
plot(boot_22_npn, order="sample")
```
```{r eval=FALSE}
# Accuracy of centrality indeces
boot_22_accuracy_EBICpcor <- bootnet(Network22_EBIC_pcor, nBoots=1000, nCores=8, type="case")
boot_22_accuracy_threshold <- bootnet(network22_pcor, nBoots=1000, nCores=8, type="case")
boot_22_accuracy_npn <- bootnet(Network22_npn, nBoots=1000, nCores=8, type="case")

```
```{r eval=FALSE}
#Zoom in on specific nodes
plot(boot_22_accuracy_EBICpcor, perNode=TRUE, "strength")
plot(boot_22_accuracy_threshold, perNode=TRUE, "strength")
plot(boot_22b, perNode=TRUE, "strength")
plot(boot_22_accuracy_npn, perNode=TRUE, "strength")

```

```{r}
##### COMPARE centrality (MAIN NETWORKS 2 with pcor with and without nonparanormal transformation, and 1 with polychoric cor without any transformation) fro 2022
centralityPlot(list(Network22_EBIC_poly=Network22_EBIC_poly,Network22_EBIC_pcor=Network22_EBIC_pcor), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
centralityPlot(list(Network22_npn=Network22_npn,Network21_npn=Network21_npn), include = c("Strength", "Betweenness", "Closeness"))
```
In networks where the nonparanomral transformation has been applied, Climate importance seems to be the most central node. Otherwise in all other networks harming future generations appears to be the most central node. 

```{r}
##### Create two new datasets 21 and 22 only with the common variables

common_vars <- intersect(names(df21recoded_subset), names(df22recoded_subset))
print(common_vars)

```

```{r}
diff_vars22 <- setdiff(names(df22recoded_subset), names(df21recoded_subset))
print(diff_vars22)

```
```{r}
diff_vars21 <- setdiff(names(df21recoded_subset), names(df22recoded_subset))
print(diff_vars21)

```
```{r}
# common vars without demographics
common_vars <- c("climate_awareness", "climate_happening", "climate_beliefs", "climate_worry", 
                 "harm_personally", "harm_future_gen", "climate_importance", "gov_priority",
                 "economic_impact", "renewable_more_less", "fossil_more_less")

data21_common <- df21recoded_subset[, common_vars]
data22_common <- df22recoded_subset[, common_vars]

write.csv(data21_common, "data21_common.csv")
write.csv(data22_common, "data22_common.csv")

```


```{r}
########### Re-estimate networks for common vars 21 and 22 with polychoric and EBIC
Network22_EBIC_poly_subset <- estimateNetwork(data22_common,default = "EBICglasso", tuning = .5, corMethod = "cor_auto")
Network21_EBIC_poly_subset<- estimateNetwork(data21_common,default = "EBICglasso", tuning = .5, corMethod = "cor_auto")
```
```{r}
png("Network21_subset.png", width = 2000, height = 1500, res = 300)

plot(Network21_EBIC_poly_subset)
```


```{r}
## Re-estimate networks for common vars 21 and 22 with npn and pcor
Network22_EBIC_npn_subset <- estimateNetwork(data22_common,default = "EBICglasso", tuning = 0.5, corMethod = "npn")
Network22_EBIC_pcor_subset <- estimateNetwork(data22_common, default = "EBICglasso",tuning = 0.5,corMethod = "cor")
Network21_EBIC_npn_subset <- estimateNetwork(data21_common,default = "EBICglasso", tuning = 0.5, corMethod = "npn")
Network21_EBIC_pcor_subset <- estimateNetwork(data21_common, default = "EBICglasso",tuning = 0.5,corMethod = "cor")
```



```{r}
pdf("CentralityPlotSubsets.pdf")
## compare common variables centrality in new estimated networks
centralityPlot(list(Network22_EBIC_poly_subset=Network22_EBIC_poly_subset,Network21_EBIC_poly_subset=Network21_EBIC_poly_subset,Network22_EBIC_npn_subset=Network22_EBIC_npn_subset,Network22_EBIC_pcor_subset=Network22_EBIC_pcor_subset,Network21_EBIC_npn_subset=Network21_EBIC_npn_subset,Network21_EBIC_pcor_subset=Network21_EBIC_pcor_subset), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
png("Network22_21_centrality.png", width = 2000, height = 1500, res = 300)
centralityPlot(list(Network22_EBIC_poly_subset=Network22_EBIC_poly_subset,Network21_EBIC_poly_subset=Network21_EBIC_poly_subset), include = c("Strength", "Betweenness", "Closeness"))
```

```{r}
centralityPlot(list(Network22_EBIC_pcor_subset=Network22_EBIC_pcor_subset,Network21_EBIC_pcor_subset=Network21_EBIC_pcor_subset), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
centralityPlot(list(Network21_EBIC_npn_subset=Network21_EBIC_npn_subset,Network22_EBIC_npn_subset=Network22_EBIC_npn_subset), include = c("Strength", "Betweenness", "Closeness"))
```

```{r}
## correlating edge weights for the 2021 subset and 2022 subset
#obtain weights matrices
w1<-Network21_EBIC_poly_subset$graph  
w2<-Network22_EBIC_poly_subset$graph

#obtain edge weights by taking lower(or upper) triangular elements
e1<-w1[lower.tri(w1)]
e2<-w2[lower.tri(w2)]

#correlated edges
cor(e1,e2)
```


```{r}
#scatter
plot(e1,e2)
```
2021 and 2022 data (common variables) seem to be highly correalted. 
```{r}
# Elbow method to determine number of clusters in 2021
library(dplyr)
library(ggplot2)

# Drop NAs from the data
data_clean <- df21recoded_subset %>% drop_na()

# Compute total within-cluster sum of square
wss <- map_dbl(1:10, function(k) {
  kmeans(data_clean, centers = k)$tot.withinss
})

# Plot the elbow
elbow_df <- data.frame(k = 1:10, wss = wss)
ggplot(elbow_df, aes(x = k, y = wss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Elbow Method for Optimal k 2021",
       x = "Number of clusters k",
       y = "Total Within-Cluster Sum of Square")
```

RUN tsne for 2021
```{r}
library(dplyr)
library(Rtsne)
library(ggplot2)

# Start with unique data, drop NAs, and sample
data21_unique <- df21recoded_subset %>%
  unique() %>%
  drop_na() %>%
  sample_n(10000, replace = FALSE)

# Set seed for reproducibility
set.seed(123)

# Run k-means clustering
k <- 3
kmeans_results <- kmeans(data21_unique, centers = k)

# Add the cluster assignments to the data21_sample data frame
data21_unique$Cluster <- as.factor(kmeans_results$cluster)

# Perform t-SNE
tsne_results <- Rtsne(data21_unique, dims = 2, perplexity = 50, 
                      verbose = TRUE, max_iter = 800, pca = TRUE)

# Convert the t-SNE results to a data frame and add the cluster assignments
tsne_df <- data.frame(tsne_results$Y, Cluster = data21_unique$Cluster)

# Name the columns
colnames(tsne_df) <- c("Dimension1", "Dimension2", "Cluster")

# Create scatter plot with ggplot2
ggplot(tsne_df, aes(x = Dimension1, y = Dimension2, color = Cluster)) +
  geom_point() +
  labs(x = "t-SNE dimension 1", y = "t-SNE dimension 2") +
  scale_color_discrete(name = "Cluster")

```
```{r}
# Determine number of clusters in 2022

data_clean2 <- df22recoded_subset %>% drop_na()

# Compute total within-cluster sum of square
wss <- map_dbl(1:10, function(k) {
  kmeans(data_clean2, centers = k)$tot.withinss
})

elbow_df <- data.frame(k = 1:10, wss = wss)
ggplot(elbow_df, aes(x = k, y = wss)) +
  geom_line() +
  scale_x_continuous(breaks = 1:10) +
  labs(title = "Elbow Method for Optimal k 2022",
       x = "Number of clusters k",
       y = "Total Within-Cluster Sum of Square")
```

Run tsne for 2022
```{r}
# Start with unique data, drop NAs, and sample
data22_unique <- df22recoded_subset %>%
  unique() %>%
  drop_na() %>%
  sample_n(10000, replace = FALSE)

# Set seed for reproducibility
set.seed(123)

# Run k-means clustering
k <- 4
kmeans_results2 <- kmeans(data22_unique, centers = k)

# Add the cluster assignments to the data21_sample data frame
data22_unique$Cluster <- as.factor(kmeans_results2$cluster)

# Perform t-SNE
tsne_results2 <- Rtsne(data22_unique, dims = 2, perplexity = 50, 
                      verbose = TRUE, max_iter = 800, pca = TRUE)

# Convert the t-SNE results to a data frame and add the cluster assignments
tsne_df2 <- data.frame(tsne_results2$Y, Cluster = data22_unique$Cluster)

# Name the columns
colnames(tsne_df2) <- c("Dimension1", "Dimension2", "Cluster")

# Create scatter plot with ggplot2
ggplot(tsne_df2, aes(x = Dimension1, y = Dimension2, color = Cluster)) +
  geom_point() +
  labs(x = "t-SNE dimension 1", y = "t-SNE dimension 2") +
  scale_color_discrete(name = "Cluster")
```
```{r eval=FALSE}
# try again with spectral clustering
# Load necessary libraries
library(kernlab)
library(cluster)

# Choose an appropriate sigma 
sigma <- 15

df21_subset_small <- df21_subset_RC[sample(1:nrow(df21_subset_RC), 1000), ]



# 1. Compute the Similarity Matrix
similarity_matrix <- matrix(0, nrow(df21_subset_small), nrow(df21_subset_small))
for (i in 1:nrow(df21_subset_small)) {
  for (j in 1:nrow(df21_subset_small)) {
    similarity_matrix[i,j] <- exp(-sum(abs(df21_subset_small[i,] - df21_subset_small[j,]))^2 / (2 * sigma^2))
  }
}


# 2. Construct the Graph Laplacian
degree_matrix <- diag(rowSums(similarity_matrix))
laplacian <- degree_matrix - similarity_matrix

# 3. Eigen Decomposition
eigen_decomp <- eigen(laplacian)
# Sorting eigenvalues and eigenvectors
sorted_indices <- order(eigen_decomp$values)
eigenvalues <- eigen_decomp$values[sorted_indices]
eigenvectors <- eigen_decomp$vectors[,sorted_indices]

# 4. Form Clusters from Eigenvectors
k <- 3
clusters <- kmeans(eigenvectors[,1:k], centers=k)$cluster



```

```{r eval=FALSE}
# perform the cluster with the finite mixture model Latent class analysis (see paper by Kacha et al (2022) which performed latent class analysis on data to identify groups of respondeds in Europe akin to the yale program on climate change communication studies  )
library(poLCA)
```


Start Looking at different networks for different demographic groups for year 2021
```{r}
# differences between female and male for data 21 (with other demographics included and no recoding for -1)

dat21<-df21recoded2_NA

# Remove 'Refused' (-1) and other and 'Prefer not to answer'
dat21 <- filter(dat21, gender != -1, gender != 2)  # Removing "Refused" and "Other/Prefer not to answer" from gender column

# Subset Data by Gender
dat21_female <- filter(dat21, gender == 0)
dat21_male <- filter(dat21, gender == 1)

#remove one level variables (so gender)
dat21_female <- select(dat21_female, -gender)
dat21_male <- select(dat21_male, -gender)
```

```{r}
# For females
net21_female_EBIC <- estimateNetwork(data = dat21_female, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
# For males
net21_male_EBIC <- estimateNetwork(data = dat21_male, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_female_EBIC, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_male_EBIC, include = c("Strength", "Betweenness", "Closeness"))
```


```{r}

dat21_subset <- df21recoded2_NA %>%
  select(-age, -urbanicity, -country)
```

```{r}
# Subset Data by Gender
dat21_female_subset<- filter(dat21_subset, gender == 0)
dat21_male_subset <- filter(dat21_subset, gender == 1)
```


```{r}
# remove one level variable 
dat21_female_subset <- select(dat21_female_subset, -gender)
dat21_male_subset <- select(dat21_male_subset, -gender)

```

```{r}
net21_female_EBIC_subset <- estimateNetwork(data = dat21_female_subset, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
net21_male_EBIC_subset <- estimateNetwork(data = dat21_male_subset, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```

```{r}
centralityPlot(net21_female_EBIC_subset, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_male_EBIC_subset, include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
centralityPlot(list(net21_female_EBIC_subset=net21_female_EBIC_subset,net21_male_EBIC_subset=net21_male_EBIC_subset), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
plot(net21_female_EBIC_subset)
plot(net21_male_EBIC_subset)
```
Not many differences between female and male particpants in 2021, except for males support for the paris agreement also seems to be quite central. 

Start Network comparison for different countries 2021 here

```{r}
#select country and other variables without the other demographics
dat21_country <- subset(df21recoded2_NA, select=-c(urbanicity,age,gender))
```

```{r}
# Filtering data for respondents from Italy
data21_italy <- filter(dat21_country, country == 13)
```

```{r}
# remove one level variable, so country
data21_italy <- select(data21_italy, -country)

```

```{r}
net21_Italy_EBIC <- estimateNetwork(data = data21_italy, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
```


```{r}
plot(net21_Italy_EBIC)
```


```{r}
centralityPlot(net21_Italy_EBIC, include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
# Filtering data for respondents from Russia
data21_Russia <- filter(dat21_country, country == 21)
data21_Russia <- select(data21_Russia, -country)
```
```{r}
net21_Russia_EBIC <- estimateNetwork(data = data21_Russia, default = "EBICglasso",tuning = 0.5, corMethod = "cor_auto")
```
```{r}
plot(net21_Russia_EBIC)
```
```{r}
centralityPlot(net21_Russia_EBIC, include = c("Strength", "Betweenness", "Closeness"))
```

```{r}
# Filtering data for respondents from Italy
data21_netherlands<- filter(dat21_country, country == 17)
```

```{r}
# remove one level variable
data21_netherlands <- select(data21_netherlands, -country)

```

```{r}
net21_netherlands_EBIC <- estimateNetwork(data = data21_netherlands, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
```
```{r}
plot(net21_netherlands_EBIC)
```
```{r}
centralityPlot(net21_netherlands_EBIC, include = c("Strength", "Betweenness", "Closeness"))
```



```{r}
# Filtering data for respondents from UK
data21_UK <- filter(dat21_country, country == 28)
data21_UK <- select(data21_UK, -country)
```

```{r}
net21_UK_EBIC <- estimateNetwork(data = data21_UK, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
data21_US <- filter(dat21_country, country == 29)
data21_US <- select(data21_US, -country)
```

```{r}
net21_US_EBIC <- estimateNetwork(data = data21_US, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_UK_EBIC, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_US_EBIC, include = c("Strength", "Betweenness", "Closeness"))
```



```{r}
centralityPlot(list(net21_US_EBIC=net21_US_EBIC,net21_UK_EBIC=net21_UK_EBIC), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
# Filter data for US and UK
subset_data_USUK <- subset(df21recoded2_NA, country %in% c(28, 29))

# Create a table of responses
response_table <- table(subset_data_USUK$country, subset_data_USUK$gov_priority)

print(response_table)

```





```{r}
png("Network21_US_EBIC.png", width = 2000, height = 1500, res = 300)
plot(net21_US_EBIC)
```

```{r}
png("Network21_UK_EBIC.png", width = 2000, height = 1500, res = 300)
plot(net21_UK_EBIC)
```

```{r}
data21_Fr <- filter(dat21_country, country == 8)
data21_Fr <- select(data21_Fr, -country)
```

```{r}
net21_Fr_EBIC <- estimateNetwork(data = data21_Fr, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_Fr_EBIC, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_Italy_EBIC, include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
plot(net21_Fr_EBIC)
```
For countries such as France and Italy, the climate importance seems to be the most central belief. For the US and UK.

```{r}
centralityPlot(list(net21_netherlands_EBIC=net21_netherlands_EBIC,net21_US_EBIC=net21_US_EBIC), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
png("Network21_US_UK_poly.png", width = 2000, height = 1500, res = 300)
centralityPlot(list(net21_US_EBIC=net21_US_EBIC,net21_UK_EBIC=net21_UK_EBIC), include = c("Strength", "Betweenness", "Closeness"))
```


```{r}
data21_india <- filter(dat21_country, country == 10)
data21_india <- select(data21_india, -country)
net21_india_EBIC <- estimateNetwork(data = data21_india, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
centralityPlot(list(net21_india_EBIC=net21_india_EBIC), include = c("Strength", "Betweenness", "Closeness"))
```


```{r}
centralityPlot(list(net21_netherlands_EBIC=net21_netherlands_EBIC,net21_US_EBIC=net21_US_EBIC,net21_UK_EBIC=net21_UK_EBIC,net21_Fr_EBIC=net21_Fr_EBIC,net21_Russia_EBIC=net21_Russia_EBIC, net21_Italy_EBIC=net21_Italy_EBIC,net21_india_EBIC=net21_india_EBIC), include = c("Strength", "Betweenness", "Closeness"))
```
2022 Country analysis

```{r}
#select country and other variables without the other demographics
dat22_country <- subset(df22recoded2_NA, select=-c(urbanicity,age,gender,education))
```

```{r}
# Filtering data for respondents from Norway
data22_Norway <- filter(dat22_country, country == 110)
```

```{r}
# remove one level variable, so country
data22_Norway <- select(data22_Norway, -country)

```

```{r}
net22_Norway_EBIC <- estimateNetwork(data = data22_Norway, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
```
```{r}
plot(net22_Norway_EBIC)
```
```{r}
data22_Albania <- filter(dat22_country, country == 102)
data22_Albania <- select(data22_Albania, -country)
net22_Albania_EBIC <- estimateNetwork(data = data22_Albania, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")

```
```{r}
data22_UK<- filter(dat22_country, country == 28)
data22_UK<- select(data22_UK, -country)
net22_UK_EBIC <- estimateNetwork(data = data22_UK, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")

data22_US<- filter(dat22_country, country == 29)
data22_US<- select(data22_US, -country)
net22_US_EBIC <- estimateNetwork(data = data22_US, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")

data22_Italy<- filter(dat22_country, country == 13)
data22_Italy<- select(data22_Italy, -country)
net22_Italy_EBIC <- estimateNetwork(data = data22_Italy, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")

data22_India<- filter(dat22_country, country == 10)
data22_India<- select(data22_India, -country)
net22_India_EBIC <- estimateNetwork(data = data22_India, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
```

```{r}

centralityPlot(list(net22_Norway_EBIC=net22_Norway_EBIC,net22_Italy_EBIC=net22_Italy_EBIC,net22_US_EBIC=net22_US_EBIC,net22_UK_EBIC=net22_UK_EBIC,net22_India_EBIC=net22_India_EBIC), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
png("Network22_US_UK_poly.png", width = 2000, height = 1500, res = 300)
centralityPlot(list(net22_US_EBIC=net22_US_EBIC,net22_UK_EBIC=net22_UK_EBIC), include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
png("Network22_UK_poly.png", width = 2000, height = 1500, res = 300)
plot(net22_UK_EBIC)
```
```{r}
png("Network22_US_poly.png", width = 2000, height = 1500, res = 300)
plot(net22_US_EBIC)
```


```{r}
# subsetting by age

# 1 Gen z
#without the other demographics and NAs
dat21_age <- subset(df21recoded2_NA, select=-c(urbanicity,country,gender))

```
```{r}
data21_age1 <- filter(dat21_age, age == 0)
data21_age1 <- select(data21_age1, -age)
```

```{r}
net21_age1 <- estimateNetwork(data = data21_age1, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_age1, include = c("Strength", "Betweenness", "Closeness"))
```
For Gen z, Climate action is more central
```{r}
# 2 millenials
data21_age2 <- filter(dat21_age, age == 1)
data21_age2 <- select(data21_age2, -age)
```

```{r}
net21_age2 <- estimateNetwork(data = data21_age2, default = "EBICglasso",tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_age2, include = c("Strength", "Betweenness", "Closeness"))
```
Same of millenials.
```{r}
# Gen x
data21_age3 <- filter(dat21_age, age == 2)
data21_age3 <- select(data21_age3, -age)
```

```{r}
net21_age3 <- estimateNetwork(data = data21_age3, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_age3, include = c("Strength", "Betweenness", "Closeness"))
```
Climate importance is more central for Gen X.
```{r}
plot(net21_age3)
```

```{r}
# 4. baby boomers
data21_age4 <- filter(dat21_age, age == 3)
data21_age4 <- select(data21_age4, -age)

```

```{r}
net21_age4 <- estimateNetwork(data = data21_age4, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_age4, include = c("Strength", "Betweenness", "Closeness"))
```
Paris support or oppose is more cental for baby boomers. 
```{r}
plot(net21_age4)
```
```{r}
# all together 21
centralityPlot(net21_age1, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_age2, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_age3, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_age4, include = c("Strength", "Betweenness", "Closeness"))
```
Clearly climate action is more central for gen Z, climate importance for millenials and Gen X, and support for Paris agreement for Baby boomers. 

```{r}
centralityPlot(list(net21_age1=net21_age1,net21_age2=net21_age2,net21_age2=net21_age2,net21_age3=net21_age3,net21_age4=net21_age4), include = c("Strength", "Betweenness", "Closeness"))
```

Age analysis for 2022 starts here
```{r}

df22_age <- subset(df22recoded2_NA, select=-c(country,urbanicity,gender))
```

```{r}
data22_age1 <- filter(df22_age, age == 0)
data22_age1 <- select(data22_age1, -age)
data22_age2 <- filter(df22_age, age == 1)
data22_age2 <- select(data22_age2, -age)
data22_age3 <- filter(df22_age, age == 2)
data22_age3 <- select(data22_age3, -age)
data22_age4 <- filter(df22_age, age == 3)
data22_age4 <- select(data22_age4, -age)
```
```{r}
net22_age1 <- estimateNetwork(data = data22_age1, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
net22_age2 <- estimateNetwork(data = data22_age2, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
net22_age3 <- estimateNetwork(data = data22_age3, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
net22_age4 <- estimateNetwork(data = data22_age4, default = "EBICglasso", tuning = 0.5,corMethod = "cor_auto")
```
```{r}
# all together 22
centralityPlot(net22_age1, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net22_age2, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net22_age3, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net22_age4, include = c("Strength", "Betweenness", "Closeness"))
```

```{r}
centralityPlot(list(net22_age1=net22_age1,net22_age2=net22_age2,net22_age3=net22_age3,net22_age4=net22_age4), include = c("Strength", "Betweenness", "Closeness"))
```
not so many age differences in 22.

Are the networks different for those who act environmentally vs those who do not? check the network differences between climate action.



```{r}
# remove demographics first
dat21_action<- subset(df21recoded2_NA, select=-c(country,urbanicity,age,gender))
# Create a table of counts for the values 0 and 4
counts <- table(dat21_action$climate_action[dat21_action$climate_action %in% c(0, 4)])
# Plot the counts
barplot(counts, main="Responses for climate_action", xlab="Response Value", ylab="Number of Respondents", col=c("red", "blue"), border="white", las=1)
legend("topright", legend=names(counts), fill=c("red", "blue"))


```
```{r}
library(dplyr)
# For those who responded with a 4 -> I am participating in an effort like this now
df21_high_action <- dat21_action %>% filter(`climate_action` == 4)

# For those who responded 0 -> I definitely would not do it
df21_low_action <- dat21_action %>% filter(`climate_action` == 0)
```

```{r}
# now remove the action variable
df21_high_action <- df21_high_action[, !(names(df21_high_action) == "climate_action")]
df21_low_action <- df21_low_action[, !(names(df21_low_action) == "climate_action")]
```

```{r}
library(bootnet)
# construct networks for high and low action
net21_high_action <- estimateNetwork(data = df21_high_action, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
net21_low_action <- estimateNetwork(data = df21_low_action, default = "EBICglasso", tuning = 0.5, corMethod = "cor_auto")
```
```{r}
centralityPlot(net21_high_action, include = c("Strength", "Betweenness", "Closeness"))
centralityPlot(net21_low_action, include = c("Strength", "Betweenness", "Closeness"))
```
```{r}
plot(net21_high_action)
```
```{r}
# Network comparison tests
library(NetworkComparisonTest)

NCT_UK_US<- NCT(net21_UK_EBIC,net21_US_EBIC, it=10, test.edges=TRUE)
```
```{r}
NCT_UK_US_c<- NCT(net21_UK_EBIC,net21_US_EBIC, test.edges=TRUE, test.centrality = TRUE, centrality = c("strength"), nodes = "all")
```
```{r}
NCT_commonvars_c<-NCT(Network21_EBIC_poly_subset,Network22_EBIC_poly_subset, it=10, test.edges=TRUE, test.centrality = TRUE, centrality = c("strength"), nodes = "all")
```
```{r}
summary(NCT_commonvars_c)
```
```{r}
# difference in global strength p.values
NCT_commonvars_c$glstrinv.real
NCT_commonvars_c$glstrinv.pval
```
```{r}
#maximum difference in edge weights
NCT_commonvars_c$nwinv.real
NCT_commonvars_c$nwinv.pval
```


```{r}
# which edges differ significantly
NCT_commonvars_c$einv.pvals[which(NCT_commonvars_c$einv.pvals[,3] < 0.05), ]
```
```{r}
NCT_commonvars_c$einv.pval
```


```{r}
layout<-averageLayout(NCT_commonvars_c$nw1,NCT_commonvars_c$nw2)
qgraph(NCT_commonvars_c$nw2, theme='colorblind', layout=layout, maximum=1.7)
qgraph(NCT_commonvars_c$nw1, theme='colorblind', layout=layout, maximum=1.7)
```


```{r}
summary(NCT_UK_US_c)
```

```{r}
# p value of global strength
NCT_UK_US$glstrinv.pval
```
The global strength of a network is the sum of the absolute edge weights in the network. The overall connectivity or co-activation in the two networks is significantly different, with a p-value <0.001

```{r}
# p value of omnibus test (check this again)
NCT_UK_US$nwinv.pval
```
The omnibus test indicates that the two networks have at least one connection that is significantly different, with a very low p-value of  p<0.001.

```{r}
# p value of edge tests
NCT_UK_US$einv.pval
```

```{r}
plot(NCT_UK_US_c, what = c("strength", "network", "edge", "centrality"))
```

```{r}
# Network comparison tests
library(NetworkComparisonTest)

NCT_action<- NCT(net21_high_action,net21_low_action, it=10, test.edges=TRUE)
NCT_action_c<- NCT(net21_high_action,net21_low_action, it=10, test.edges=TRUE,test.centrality = TRUE, centrality = c("strength"), nodes = "all")
```
```{r}
summary(NCT_action_c)
```
```{r}
NCT_action_c$glstrinv.real
NCT_action_c$glstrinv.pval
```



```{r}
plot(NCT_action_c, what = c("strength", "network", "edge", "centrality"))
```

```{r}
# p value of global strength
NCT_action_c$glstrinv.pval
```
 The overall connectivity or co-activation in the two networks is significantly different, with a p-value <0.001

```{r}
# p value of omnibus test (check this again)
NCT_action_c$nwinv.pval
```
The omnibus test indicates that the two networks have at least one connection that is significantly different, with a very low p-value of  p<0.001.

```{r}
# p value of edge tests
NCT_action_c$einv.pval
```

```{r}
# Community detections
library(EGAnet)
ega1<-EGA(df21recoded_subset, plot.EGA = TRUE)
```



Simulation tests begin here. we want to see in 2021 the effect of intervening on harm_future_gen on climate_action
```{r}
# create a copy of the dataset 
df21recoded_subset_copy <- df21recoded_subset

# Number of simulations
num_sims <- 1000

# Extract the adjacency matrix from the network
adj_matrix <- Network21_EBIC_poly$graph

# Initialize a matrix to store results (e.g., effects on climate_action)
results <- matrix(NA, nrow=num_sims, ncol=4, dimnames=list(NULL, c("harm_0", "harm_1", "harm_2", "harm_3")))

# Index for harm_future_gen and climate_action
index_harm <- which(colnames(df21recoded_subset_copy) == "harm_future_gen")
index_climate <- which(colnames(df21recoded_subset_copy) == "climate_action")

for (i in 1:num_sims) {
  for (harm_value in 0:3) {
    # Set harm_future_gen to the intervention value
    intervention_vector <- rep(0, ncol(df21recoded_subset_copy))
    intervention_vector[index_harm] <- harm_value
    
    # Calculate the effect on climate_action (and potentially other nodes)
    effect <- sum(intervention_vector * adj_matrix[, index_climate])
    
    # Store the result
    results[i, paste("harm", harm_value, sep="_")] <- effect
  }
}
```


```{r}
# Analyze the 'results' matrix to see the distribution of effects on climate_action for each intervention value.
summary_results <- apply(results, 2, summary)

par(mfrow=c(2,2))  # Set up a 2x2 plotting grid
for (col in colnames(results)) {
  hist(results[,col], main=col, xlab="Effect on climate_action", breaks=30)
}

```
```{r}
boxplot(results, main="Effects on climate_action by harm_future_gen value", ylab="Effect on climate_action")

```





